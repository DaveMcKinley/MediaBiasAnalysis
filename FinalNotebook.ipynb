{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cd2e24",
   "metadata": {},
   "source": [
    "### Business Overview\n",
    "\n",
    "Oxford dictionry descrives an echo chamber as, \"an environment in which somebody encounters only opinions and beliefs similar to their own, and does not have to consider alternatives.\" According to this Pe Study https://www.pewresearch.org/journalism/2021/01/12/news-use-across-social-media-platforms-in-2020/, 53% of American Adults say they get news from social media “often” or “sometimes,”. And, this https://www.pnas.org/content/118/9/e2023301118 2021 National Academy of Sciences study on echo chambers on social media platforms found \"the aggregation of users in homophilic clusters dominate online interactions on Facebook and Twitter.\" While social media sites need to take some of the responsibility, I want to take a look at the content being shared and discussed within the echo chambers. It is important to take a look at what information and messaging is being spread with the echo chambers. An article in Scientific American https://www.scientificamerican.com/article/why-social-media-makes-us-more-polarized-and-how-to-fix-it/ discusses how social media, specifically social media influencers, have a disproportionate impact on their communities. I am not investigating how these influencers came to be. I am interested in what they are sharing in the space.\n",
    "\n",
    "The good people at Allsides.com try to help people \"easily identify different perspectives so you can get the full picture and think for yourself.\" Today's media is very biased. And a lot of media sources are very acessible. As shown in National Academy of Sciences Paper, newsfeeds are often an echo chamber based on thier history of related articles and newsites, especially on Facebook. By nature, echo chambers remove media sources outside of someone's chamber, making it difficult to understand different view points regarding news events.\n",
    "\n",
    "A Stanford article https://news.stanford.edu/2019/08/22/the-power-of-language-how-words-shape-people-culture/ points out \"Studying how people use language – what words and phrases they unconsciously choose and combine – can help us better understand ourselves and why we behave the way we do.\" By paying attention to the words used in a article, the reader can critically think about what the article is presenting. Know what words and terms determine bias creates trasparency about topics in the article. The reader can know certain words and phrases are used in different biased articles and go deeper into the article to think about why the author used the words they did, or what message are they sending by using that word. Helping people become aware of what words and phrases drive bias in news media content can help the people understand the both sides of an argument.\n",
    "\n",
    "People who do want to explore both side of an argument may visit a site like AllSides.com to guage a news site's bias. Allsides uses many methods to rate bias, including third party data with the requirement of transparency in the system. I have developed a model to determine bias in a corpus of news articles based on the laguage used in each article. To add transparency and explainability to my model I have utilized LIME to show what words and phrases leading to a better understanding of media bias and more informed readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ddf7c",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Source: I would have liked to use one dataset, however, the computational cost was too high which lead me to shrinking the size of the dataset. This data was gathered from https://components.one/datasets/all-the-news-2-news-articles-dataset/ and https://www.kaggle.com/snapcrack/all-the-news. The Kaggle dataset was created from the original source site but different for a different database. The DataFrames contained the same content and allowed me to use information from both to develop the working DataFrame.\n",
    "\n",
    "I began by looking at the data and understanding I would only be able to predict left, center or right. I did not have enough data to make a 5 class predictor. From there I decided to select two left foused, two center focused and two right focused media outlets. The news sources were determined by looking at MediaBias/Fact Check and Allsides.com Media Bias lists and selecting sources that each independent side agreed on. After selecting my sources, I began to gather the articles in one DataFrame.\n",
    "\n",
    "I started to gather information for my Dataframe in the WorkingDF noteboook. I decided to go with two sources for each category of bias. The sources do not have an equal number of articles. And each bias is not an equal split. The Kaggle Dataset had all the sources I needed for the right leaning articles and one source for the center and left biases. I imported each csv file from Kaggle and selected the sources I needed. I then flipped over to the split notebook. Due to the size of the dataset, I randomly selected 35 percent of the 2.7 million articles in the compnents dataset. I then to pulled stories from Vox and The Hill. To maintain class balance, I randomly select between 16,000 and 17,000 texts pulished on The Hill's website. I then pickled the two dataframes and imported them into the WorkingDF notebook. I then combined all of the dataframes into one woring DataFrame. I then pickled my working DataFrame and imported into the EDA/preprocessing notebook. Once I processed the data for modeling I again pickled the processed DataFrame and loaded it into the Modeling notebook. For this notebook I have pulled the unprocessed Workiong DataFrame to elaborate on my preprocessing steps. In total, I gathered approximately 85,000 articles from from the two datasets. Each row contains an article, publisher and bias label. For modeling I will use the article and bias.\n",
    "\n",
    "This data set could be used to its full potential with better computing power. The article corous also has a limited amount of right leaning news sources. There is an abundance of left leaning sources. With a greater variety of sources, I would like to expand this classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from itertools import islice\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot(df, col, hue=None, rotation=None, order=None):\n",
    "    \"\"\"\n",
    "    This function builds a Seaborn countplot and allows the user to set certain parameters to customize the graph.\n",
    "    \n",
    "    df - dataframe being used\n",
    "    col- column in dataframe being used\n",
    "    hue - second column being used(if any)\n",
    "    rotation - sets the rotation of the x-ticks for readability\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    sns.countplot(data = df, x = col, hue = hue, order = order)\n",
    "    ax.set_xticklabels(labels = ax.get_xticklabels(), rotation= rotation, fontsize = 15)\n",
    "    ax.set_xlabel(xlabel = col, fontsize = 20)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "    ax.set_ylabel(ylabel = \"Number of articles\", fontsize = 20)\n",
    "    ax.set_title(f\"Number of articles per {col}\", fontsize = 30)\n",
    "    plt.show()\n",
    "    \n",
    "def evaluate(model, X_tr, y_tr, X_te, y_te):\n",
    "    print('Accuracy Score:')\n",
    "    print(f'Train - {accuracy_score(y_tr, model.predict(X_tr))}')\n",
    "    print(f'Test - {accuracy_score(y_te, model.predict(X_te))}')\n",
    "    print('  ')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_te, model.predict(X_te)))\n",
    "    print('Confusion matrix for test data')\n",
    "    return plot_confusion_matrix(model, \n",
    "                                 X_te, y_te, \n",
    "                                 include_values=True, \n",
    "                                 display_labels =  [\"Left\", \"Center\", \"Right\"], \n",
    "                                 cmap=plt.cm.Blues)\n",
    "\n",
    "def create_embedding_matrix(glove_filepath, word_index, embedding_dim):\n",
    "    '''\n",
    "    Grabs the embeddings just for the words in our vocabulary\n",
    "    \n",
    "    Inputs:\n",
    "    glove_filepath - string, location of the glove text file to use\n",
    "    word_index - word_index attribute from the keras tokenizer\n",
    "    embedding_dim - int, number of dimensions to embed, a hyperparameter\n",
    "    \n",
    "    Output:\n",
    "    embedding_matrix - numpy array of embeddings\n",
    "    '''\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(glove_filepath, encoding=\"UTF-8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "def visualize_training_results(history):\n",
    "    '''\n",
    "    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "    \n",
    "    Input: keras history object (output from trained model)\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "    fig.suptitle('Model Results')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['train', 'test'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take engineered dataframe from pickle \n",
    "df = pd.read_pickle(\"../data/df.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ef960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a look at  the legnths of each article\n",
    "df['word_count'] = df[\"Content\"].apply(lambda x: len(nltk.word_tokenize(str(x))) )\n",
    "df['char_count'] = df[\"Content\"].apply(lambda x: sum(len(word) for word in nltk.word_tokenize(str(x))) )\n",
    "df['sentence_count'] = df[\"Content\"].apply(lambda x: len(nltk.sent_tokenize(str(x))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ba825",
   "metadata": {},
   "source": [
    "I limit the articles to at least 50 words and no more than 5000 words. Limiting the corpus cleans out content willed with meaningless content sunch as random characters or advertsiments and larger contents that are filled with a stream of breaking news updates rather than written articles. There can be another project in investigating live tweets of a news story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"word_count\"] < 5000) & (df[\"word_count\"] > 50)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46767a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is anything null?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many atcles per publication?\n",
    "df[\"Publication\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe55a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many atcles per Bias?\n",
    "df[\"Bias\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of Articles per Bias in Dataset:\")\n",
    "df[\"Bias\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510736b5",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of articles per publication\n",
    "countplot(df, \"Publication\", order = df[\"Publication\"].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987698c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of articles per publication\n",
    "countplot(df, \"Bias\", order = [\"Left\", \"Center\", \"Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e04d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group \n",
    "df_plot = df.groupby(['Publication', 'Bias']).size().reset_index().pivot(columns='Publication', index='Bias', values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_plot.reindex([\"Left\", \"Center\", \"Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.plot(kind='bar', stacked=True, figsize=(20,10))\n",
    "plt.xticks(rotation=\"horizontal\", fontsize = 30)\n",
    "plt.xlabel(xlabel = \"Bias\", fontsize = 40)\n",
    "plt.yticks(rotation=\"horizontal\", fontsize = 30)\n",
    "plt.ylabel(ylabel = \"Number of Articles\", fontsize = 40)\n",
    "plt.title(label= \"Number of Articles per Publication per Bias\", fontsize = 40)\n",
    "plt.legend(bbox_to_anchor=(1.3, 1), loc=\"upper right\", ncol=1, fontsize= 25, title = \"Publication\", title_fontsize= 35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the distribution of number of words in each article\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "hp = sns.histplot(data = df, x=\"word_count\", hue = \"Bias\", kde=True)\n",
    "ax.set_xlabel(xlabel = \"Number of words\", fontsize = 20)\n",
    "ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "ax.tick_params(axis='x', which='major', labelsize=15)\n",
    "ax.set_ylabel(ylabel = \"Number of articles\", fontsize = 20)\n",
    "ax.set_title(f\"Number of words per article\", fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the distribution of number of characters in each article\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.histplot(data = df, x=\"char_count\", hue = \"Bias\")\n",
    "ax.set_xlabel(xlabel = \"Number of words\", fontsize = 20)\n",
    "ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "ax.tick_params(axis='x', which='major', labelsize=15)\n",
    "ax.set_ylabel(ylabel = \"Number of articles\", fontsize = 20)\n",
    "ax.set_title(f\"Number of characters per article\", fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad024e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the distribution of number of sentences in each article\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.histplot(data = df, x=\"sentence_count\", hue = \"Bias\", bins = 100, kde = True)\n",
    "ax.set_xlabel(xlabel = \"Number of words\", fontsize = 20)\n",
    "ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "ax.tick_params(axis='x', which='major', labelsize=15)\n",
    "ax.set_ylabel(ylabel = \"Number of articles\", fontsize = 20)\n",
    "ax.set_title(f\"Number of sentences per article\", fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e6c13",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79811143",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72739bb5",
   "metadata": {},
   "source": [
    "I went through a series of operations to preprocess the data for Machine Learning. The first step was to encode the bias with a -1 for left, 0 for center and 1 for right. <br>\n",
    "\n",
    "In the preprocessing step of the project I followed these steps:\n",
    "\n",
    "- Lower case each word\n",
    "- Remove unwanted noise from the article(such as Twitter mentions, web adresses and other content)\n",
    "- Remove all numbers\n",
    "- Tokenize the list\n",
    "- Remove common stop words and punctuation\n",
    "- Lemmatizes each word\n",
    "- Returns a string of the remaining lemmatized words\n",
    "\n",
    "Fist I lowercase all the words to simplfy cleaning process. I then remove noice like mentions(@abc1123), hastags(#), and urls because they do not add anything to analysis. I also remove information at the end of The Hill's articles because it is contact information and does not help with analysis. Numbers are removed because they have no context by themselves. We tokenize the list and remove any common stopwords and punctuation. Tokenizing a list is breaking each element in the list into its own list object. Next, I lemmatized the remaining words and combines the tokens back into a string to be vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data set\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee736a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass the bias column\n",
    "dict_sent = {'Left':-1, \n",
    "             'Center':0,\n",
    "             'Right':1}\n",
    "df[\"num_bias\"] = df[\"Bias\"].map(dict_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ae3f",
   "metadata": {},
   "source": [
    "Check all three labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[45000:45005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626259c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de478f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the Tokenizer and Lemmatizer\n",
    "tokenizer = RegexpTokenizer(r\"(?u)\\b\\w\\w+\\b\")\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5134bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of new sources to add to stopwords list\n",
    "source = list(df[\"Publication\"].unique())\n",
    "source = (map(lambda x: x.lower(), source))\n",
    "source = list(source)\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stopwords_list, adds punctuation and the news sources to list\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "stopwords_list += string.punctuation\n",
    "stopwords_list += source\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex expressions to remove unwanted noise\n",
    "pattern_mentions = \"((@[a-zA-Z0-9_-]+)((?=\\s+)|$|[!?.,-]))\"\n",
    "pattern_views =  \"((the views expressed by)([\\s\\S]*)$)\"\n",
    "pattern_thread = \"((view the discussion thread.)([\\s\\S]*)$)\"\n",
    "pattern_url = \"(http\\S+)\"\n",
    "pattern_num = \"([\\d.])\"\n",
    "pattern_pic = \"((pic.)?twitter\\.com\\/[A-Za-z0-9_]{5,1000}(\\?(\\w+=\\w+&?)*)?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random article in the corpus will use to check the preprocessing step\n",
    "test = df[\"Content\"].iloc[random.randint(0,df.shape[0])]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase text\n",
    "test = test.lower()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cbb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes Twitter mentions\n",
    "test = re.sub(pattern_mentions,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7433f",
   "metadata": {},
   "source": [
    "The Hill articles end with \"the views expressed by\" or \"view the discussion thread\" both are followed by some contact information. I decided to remove these elements to prevent mis weighing words later in the Vectorizing stage of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492aef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the end of The Hill articles starting at the phrase \"the views expressed by\"\n",
    "test =  re.sub(pattern_views,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the end of The Hill articles starting at the phrase \"view the discussion thread\"\n",
    "test =  re.sub(pattern_thread,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes hyperlinks starting with http\n",
    "test =  re.sub(pattern_url,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes numbers from the text.\n",
    "test =  re.sub(pattern_num,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e859eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes pic.twitter urls\n",
    "test =  re.sub(pattern_pic,\"\", test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f432d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "test = tokenizer.tokenize(test)\n",
    "test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88beb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "stopwords_removed=[token for token in test if token not in stopwords_list]\n",
    "stopwords_removed[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize the remaing words\n",
    "lemma_list = [lemma.lemmatize(token) for token in stopwords_removed]\n",
    "lemma_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ee1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "test = df[\"Content\"].iloc[random.randint(0,df.shape[0])]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fdebf",
   "metadata": {},
   "source": [
    "### Vectorizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9cc2f",
   "metadata": {},
   "source": [
    "Once there is a string of processsed data. I use a Term Frequency-Inverse Document Frequency (TFIDF) vectorizer to vectorize the documents. The TF-IDF Vectorizer weight is found by measuring the Term Frequency and Inverse Document Frequency. Term frequency is how many times a term appears in the docuemnt divded my the number of terms in document. The Inverse Document Frequency is the log loss of the total number of documents divided by the number of documents with the term in it. It is based on the idea that rare words contain more information about the content of a document than words that are used many times throughout all the documents. Now our corpus of articles is ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ffe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and fit the count vectorizer\n",
    "cvec = CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=2000, max_df=.5, min_df= 10)\n",
    "cvec.fit(X_train[\"processed_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize, fit and transform the data\n",
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocess, max_features= 2000, \n",
    "                            ngram_range= (1,2),\n",
    "                            max_df = .5, min_df = 10))\n",
    "\n",
    "tfidf_vectorizer.fit(X_train[\"Content\"])\n",
    "X_train_tfidf_vec = tfidf_vectorizer.transform(X_train[\"Content\"])\n",
    "X_val_tfidf_vec = tfidf_vectorizer.transform(X_val[\"Content\"])\n",
    "#returna a dataframe using the count vectorizer to label to the columns rather than usless numbers.\n",
    "X_train_tfidf_vec_df = pd.DataFrame(X_train_tfidf_vec.toarray(),columns=cvec.get_feature_names(), \n",
    "                              index=X_train.index)\n",
    "X_val_tfidf_vec_df = pd.DataFrame(X_val_tfidf_vec.toarray(), columns=cvec.get_feature_names(), \n",
    "                              index=X_val.index)\n",
    "\n",
    "X_train_tfidf_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What the dataframe will look like for modeling\n",
    "X_train_tfidf_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91622de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_tfidf_vec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40189c7b",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "For this project I explored many different models. To keep things short in this notebook I have showcased a baseline, simple and 3 models followed by my final model and evaluation. You can find the rest of the models along with tuning in the Modeling Notebook in the Notebooks folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35cddb",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb843f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we were to randomly guess bias \n",
    "y_train.value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c3b8e",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91adee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up pipeline\n",
    "lr = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer('vect', TfidfVectorizer(preprocessor=preprocess, max_features= 2000, \n",
    "                            ngram_range= (1,2)))),\n",
    "    ('clf', LogisticRegression(multi_class=\"multinomial\", random_state=seed))\n",
    "                                                    ])\n",
    "#fit to training data\n",
    "lr.fit(X_train[\"Content\"], y_train)\n",
    "\n",
    "print(lr.score(X_train[\"Content\"], y_train))\n",
    "print(lr.score(X_val[\"Content\"], y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8b278",
   "metadata": {},
   "source": [
    "### Grid Search/Cross Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ca88b",
   "metadata": {},
   "source": [
    "To save on computational costs in this notebook, I have only included the best performing parameters. All of the parameters explored are in the modeing notbook. I have also used 3 cross validation folds due to the size and cost of running for folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da29a6",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "In the grid search, I added Ridge regression to adjust the weights of the coeffecients. I increased the max iterations.I looked at the regularization strength to see how much regression to effect. the solver hyperparameter was limited to 'newton-cg', 'sag', 'saga' and 'lbfgs' for muticlass problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(preprocessor=preprocess, max_features= 2000, \n",
    "                            ngram_range= (1,2),\n",
    "                            max_df = .5, min_df = 10)),\n",
    "    ('clf', LogisticRegression(multi_class=\"multinomial\", random_state=seed)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__penalty': [\"l2\"],\n",
    "    'clf__max_iter': [1000],\n",
    "    'clf__C': [1],\n",
    "    'clf__solver': ['newton-cg']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(lr_tuned, param_grid, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ef9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = grid.fit(X_train[\"Content\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = output.best_estimator_\n",
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_lr, X_train[\"Content\"], y_train, X_val[\"Content\"], y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d33edc",
   "metadata": {},
   "source": [
    "### LIME\n",
    "It is important to develop an accurate model. But just as important is the explainability of the model. As more complex models are used for analysis, the level of interpertability decreases. It is difficult to explain how certain models, like a neural network, work under the hood. Opening the black box of accurate complex models is an important aspect of this project. While I do want to accurately predict bias, I also want to understand what is driving decision making and be able to showcase what words are driving decisions.\n",
    "### TextBlob\n",
    "TextBlob is another NLP package. It is built on Stanford's NLTK module. I use TextBlob's Polarity and Subjectivity score to give the reader more insight into the article. Polarity is on a 1 to -1 scale where 1 means positive statement and -1 means a negative statement.Subjectivity is rated on a 0 to 1 scale where 0 means highly objective and 1 means highly subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a379035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code was found at https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html\n",
    "idx = random.randint(0,X_val.shape[0])\n",
    "class_names=[\"Left\", \"Center\", \"Right\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(str(X_val[\"Content\"][idx]), best_lr.predict_proba, num_features=3, labels=[0, 1, 2])\n",
    "print(f'Document id: {idx}')\n",
    "print(f'Predicted bias : {class_names[best_lr.predict(list(X_val[\"Content\"][idx])).reshape(1,-1)[0,0]]}')\n",
    "print(f'True bias: {class_names[y_val[idx]]}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).subjectivity}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).polarity}')\n",
    "exp.show_in_notebook(text=X_val[\"Content\"][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71592c21",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "For the decision tree I decided to explore the depth of the tree, how many samples in each leaf and how many samples to split at internal node. I adjusted these features because the previous model was very overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fccad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tuned = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(max_features= 2000, \n",
    "                            ngram_range= (1,2),\n",
    "                            max_df = .5, min_df = 10)),\n",
    "    ('clf', DecisionTreeClassifier(random_state=seed)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__max_depth': [25],\n",
    "    'clf__min_samples_leaf': [10],\n",
    "    'clf__min_samples_split': [5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(dt_tuned, param_grid, return_train_score=True,cv =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f462477",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = grid.fit( X_train[\"Content\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt= output.best_estimator_\n",
    "best_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(output.best_estimator_, X_train[\"Content\"], y_train, X_val[\"Content\"], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,X_val.shape[0])\n",
    "class_names=[\"Left\", \"Center\", \"Right\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(str(X_val[\"Content\"][idx]), best_dt.predict_proba, num_features=6, labels=[0, 1, 2])\n",
    "print(f'Document id: {idx}')\n",
    "print(f'Predicted bias : {class_names[best_dt.predict(list(X_val[\"Content\"][idx])).reshape(1,-1)[0,0]]}')\n",
    "print(f'True Bias: {class_names[y_val[idx]]}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).subjectivity}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).polarity}')\n",
    "exp.show_in_notebook(text=X_val[\"Content\"][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79906cfb",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "For the XGboost Model I explored alot of hyperparameters to try and reduce overfitting, however due to time contraints I had to move on to other tasks. I tried to increase the min_child_weight and max_depth was limited to prevent to prune the tree. The learning_rate was adjusted to optimize the Gradient Descent.N-estimators controlls the number of trees to make for each boosting round. colsample_bytree is to limit how much information the model takes in each boosting round. and alpha and lambda control the Ridge and Lasso regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(preprocessor=preprocess, max_features= 2000, \n",
    "                            ngram_range= (1,2),\n",
    "                            max_df = .5, min_df = 10)),\n",
    "    ('clf', XGBClassifier(random_state=seed, n_jobs = 4))])\n",
    "\n",
    "param_grid = {\n",
    "            'clf__min_child_weight': [10],\n",
    "            'clf__max_depth': [15],\n",
    "            'clf__learning_rate': [0.1],\n",
    "            'clf__n_estimators': [100],\n",
    "            'clf__colsample_bytree': [0.3],\n",
    "            'clf__reg_alpha': [10],\n",
    "            'clf__reg_lambda': [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(xgb_tuned, param_grid, return_train_score=True, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = grid.fit(X_train[\"Content\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = output.best_estimator_\n",
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_xgb, X_train[\"Content\"], y_train, X_val[\"Content\"], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,X_val.shape[0])\n",
    "class_names=[\"Left\", \"Center\", \"Right\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(str(X_val[\"Content\"][idx]), best_xgb.predict_proba, num_features=5, top_labels=3)\n",
    "print(f'Document id: {idx}')\n",
    "print(f'Predicted bias : {class_names[best_xgb.predict(list(X_val[\"Content\"][idx])).reshape(1,-1)[0,0]]}')\n",
    "print(f'True Bias: {class_names[y_val[idx]]}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).subjectivity}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).polarity}')\n",
    "exp.show_in_notebook(text=X_val[\"Content\"][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee7db2",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the length of the longest article\n",
    "max_length = max([len(s.split()) for s in X_train[\"Content\"]])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fca125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizes and vectoizes text \n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X_train[\"Content\"])\n",
    "\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train[\"Content\"])\n",
    "X_val_token = tokenizer.texts_to_sequences(X_val[\"Content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6456031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neeed for dimensions in the neural network\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pads the documents to make sure they are all the same length\n",
    "X_train_processed = keras.preprocessing.sequence.pad_sequences(\n",
    "    X_train_token, maxlen=max_length, padding='post')\n",
    "X_val_processed = keras.preprocessing.sequence.pad_sequences(\n",
    "    X_val_token, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3710847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target column\n",
    "y_train2 = to_categorical(y_train)\n",
    "y_val2 = to_categorical(y_val)\n",
    "\n",
    "#vcheck that target column has been converted\n",
    "y_val2[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192711f2",
   "metadata": {},
   "source": [
    "I will use the GloVE pretrained embedder for this network. The GloVE file to large for Git Hub, can be found here: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets up the embedding dictionary\n",
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('../data/glove.6B.50d.txt',\n",
    "                                           tokenizer.word_index, \n",
    "                                           embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(name=\"tuned\")\n",
    "#Sets the first layer with the embedding dictionary\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=max_length, \n",
    "                           trainable=False))\n",
    "#dropout half of the nodes randomly\n",
    "model.add(Dropout(0.5))\n",
    "#a simple dense layer\n",
    "model.add(layers.Dense(15, activation='relu'))\n",
    "# flattening these layers down before connecting to dense layer\n",
    "model.add(layers.Flatten()) \n",
    "#final output layer. using softmax because it is a multiclass problem\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "#compile the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "history = model.fit(X_train_processed, y_train2,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(X_val_processed, y_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9da7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize_training_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39112/1427018151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvisualize_training_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'visualize_training_results' is not defined"
     ]
    }
   ],
   "source": [
    "#display accuracy and loss scores\n",
    "visualize_training_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,X_val.shape[0])\n",
    "class_names=[\"Left\", \"Center\", \"Right\"]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(str(X_val[\"Content\"][idx]), best_xgb.predict_proba, num_features=5, top_labels=3)\n",
    "print(f'Document id: {idx}')\n",
    "print(f'Predicted bias : {class_names[best_xgb.predict(list(X_val[\"Content\"][idx])).reshape(1,-1)[0,0]]}')\n",
    "print(f'True Bias: {class_names[y_val[idx]]}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).subjectivity}')\n",
    "print(f'Subjectivity Score: {TextBlob(X_val[\"Content\"][idx]).polarity}')\n",
    "exp.show_in_notebook(text=X_val[\"Content\"][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b3e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da1440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68eb31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e4e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4827b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867f3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e719b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5759733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fac4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedb8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476375b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d2e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23aec32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5207e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f816b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b63dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5622204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb210bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b14c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957e435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f8e5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5399f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc0018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e5859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb511e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92318086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d21cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab1da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc7f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1eb5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31faffab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed5db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11daaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64dc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a931448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb9f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e387dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd3a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3ca3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401de68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8742080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731e468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0292f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87f3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddd6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0098e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ddf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa4b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67539110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59706b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b378b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b0210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546c20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17431aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
